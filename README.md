# ft_linear_regression

> A clean, single-variable linear regression model trained with batch gradient descent. It predicts car prices from mileage using only Pythonâ€™s standard library.

This project is an implementation of linear regression from scratch as required by the 42 school curriculum. The goal is to build the model without relying on NumPy, scikit-learn, or any other machine learning libraries.

---

## ğŸ³ Dockerized Environment

In strict adherence to the **"System Isolation"** guideline, this project is fully containerized. 
It does **not** pollute your local shell with `pip` packages or virtual environments.

* **Isolation:** Runs in a pristine `python:3.11-slim` container.
* **Reproducibility:** Guarantees identical results on every machine.
* **Persistence:** Trained models (`thetas.json`) are saved to your local host machine via volume mounting.

## ğŸš€ Setup and Quick Start

1.  **Prerequisite:** Ensure **Docker** is installed and running.


2.  **Train the model:**
    ```bash
    make
    ```

3.  **Predict a price:**
    ```bash
    make predict
    ```

4.  **Run bonus visualizations and metrics:**
    ```bash
    make bonus
    ```

## âš™ï¸ Custom Parameters

    Parameters  Default  Description

    ALPHA       0.05     Learning Rate (step size)
    EPOCHS      20000    Number of training iterations

**Example Usage:**
```bash
# Train with custom hyperparameters
make train ALPHA=0.01 EPOCHS=50000

# Predict a value
make predict
Enter a mileage (km): 100000
Estimated price: 6123.45 euros
```

***ğŸ“‚ Project Structureft_linear_regression/***
```bash
â”‚
â”œâ”€â”€ train.py                # Trains the model parameters Î¸â‚€ and Î¸â‚
â”œâ”€â”€ predict.py              # Predicts a price based on a given mileage
â”œâ”€â”€ data.csv                # Training dataset
â”œâ”€â”€ thetas.json             # Stores the learned parameters
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ linear_regression/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ model.py        # Core logic (data I/O, gradient descent, prediction)
â”‚
â”œâ”€â”€ bonus/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ plot.py             # Generates a scatter plot with the regression line
â”‚   â””â”€â”€ precision.py        # Computes RÂ², MSE, and RMSE metrics
â”‚
â”œâ”€â”€ Dockerfile              # Environment definition
â””â”€â”€ Makefile                # Commands for build, clean, re, and bonus
```
## ğŸ§  Algorithm Summary

Hypothesis Function:
```bash
Å· = Î¸â‚€ + Î¸â‚ * x
```

Where Å· is the predicted price, x is the mileage, and Î¸â‚€ (intercept) and Î¸â‚ (slope) are the model parameters.

Batch Gradient Descent:
```bash
Î¸â‚€ := Î¸â‚€ - Î± * (1/m) * Î£(Å· - y)
Î¸â‚ := Î¸â‚ - Î± * (1/m) * Î£(Å· - y) * x
```

Where:
- Î± is the learning rate
- m is the number of training samples
- y is the actual price

The goal is to find Î¸â‚€ and Î¸â‚ that minimize the Mean Squared Error (MSE).

Feature Standardization:
To improve numerical stability and speed up convergence, the mileage feature (x) is standardized before training using the formula:
```bash
z = (x - Î¼) / Ïƒ
```

Where Î¼ is the mean of all mileage values and Ïƒ is the standard deviation.
After training, the final parameters Î¸â‚€ and Î¸â‚ are converted back to original units for real-world predictions:
```bash
Î¸â‚ = b / Ïƒ
Î¸â‚€ = a - (b * Î¼ / Ïƒ)
```
---

## âœ¨ Bonus Programs

```bash
bonus/plot.py:
```
Generates a scatter plot of the training data and overlays the regression line.
The output is saved as ```regression_plot.png```.

```bash
bonus/precision.py:
```
Computes the modelâ€™s performance using three key metrics:

- Coefficient of Determination (RÂ²): Measures how much variance in the price can be explained by mileage.
  RÂ² = 1 means perfect fit; RÂ² = 0 means no better than predicting the mean; RÂ² < 0 means worse than the mean.

- Mean Squared Error (MSE): Average of squared differences between predicted and actual values.

- Root Mean Squared Error (RMSE): The square root of MSE, giving the error in euros.

Typical Results After Training:
```bash
RÂ² score â‰ˆ 0.73
MSE      â‰ˆ 445000
RMSE     â‰ˆ 667â‚¬
```

---

## ğŸ› ï¸ Makefile Commands

```bash
make              -> Train the model and save thetas.json
make train        -> Train the model with custom parameters (ALPHA= , EPOCHS=)
make predict      -> Run the interactive price predictor
make bonus        -> Run both bonus scripts (plot and precision)
make clean        -> Remove caches, __pycache__, and generated images
make fclean       -> Perform a full clean, also removing thetas.json
make re           -> Run fclean then retrain from scratch
make lint         -> Run a static code check using Pyflakes
```

---

## ğŸ” Troubleshooting

Problem: ```Î¸â‚€``` or ```Î¸â‚``` are NaN after training
Cause: The learning rate ```Î±``` is too high, causing divergence.
Fix: Reduce ```Î±``` (e.g., try 0.01 or 0.001).

Problem: RÂ² score is negative
Cause: The model has not converged and performs worse than the mean baseline.
Fix: Increase the number of ```epochs``` or reduce ```Î±```.

Problem: ```matplotlib``` not found
Cause: Dependencies not installed.
Fix: Run ```pip install -r requirements.txt```.

---

## ğŸ“œ License and Credits

This is an educational project for the 42 school curriculum.
Author: William Nguyen
The model is built entirely with Pythonâ€™s standard library. No external ML frameworks were used, and matplotlib is used only for bonus visualizations.
